{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "import random\n",
    "import csv\n",
    "# import cv2\n",
    "# import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script for reading data from pickle files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Train_data:</b> A list of 8000 images of size 28x28 pixels. <br>\n",
    "<b>Train_labels:</b> A list of 8000 labels each corresponding to its image present in Train_data. <br>\n",
    "<b>Test_data:</b> A list of test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data = None\n",
    "Train_labels = None\n",
    "Test_data = None\n",
    "with open(\"train_image.pkl\", \"rb\") as reader:\n",
    "    Train_data = (pickle.load(reader))\n",
    "with open(\"train_label.pkl\", \"rb\") as reader:\n",
    "    Train_labels = (pickle.load(reader))\n",
    "with open(\"test_image.pkl\", \"rb\") as reader:\n",
    "    Test_data = (pickle.load(reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\"> The following augmentation sequence was used to increase the number of images for application of neural networks. However, there was no significant improvement over other methods. Therefore, this approach was disregarded from the final classification procedure.<br>\n",
    "The transformation sequence included cropping, affine transformation, flipping, addition of noise and blur and changes in contrast and brightness. This script generated 8000 new images.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imgaug\n",
    "# from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_data = np.array(Train_data)\n",
    "# Train_data = np.reshape(Train_data, (len(Train_data), 28, 28, 1))\n",
    "# Train_data = Train_data.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgaug.seed(1)\n",
    "# seq = iaa.Sequential([iaa.Fliplr(0.5), iaa.Crop(percent=(0, 0.1)), iaa.Sometimes(0.5,iaa.GaussianBlur(sigma=(0,0.5))), iaa.ContrastNormalization((0.75, 1.5)), iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), iaa.Multiply((0.8, 1.2), per_channel=0.2), iaa.Affine(scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, rotate=(-25, 25), shear=(-8, 8))], random_order=True)\n",
    "# Train_data_aug = seq.augment_images(Train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_data = np.append(Train_data, Train_data_aug, axis=0)\n",
    "# Train_labels = np.append(Train_labels, Train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_data = np.reshape(Train_data, (len(Train_data), 784))\n",
    "# Train_data = Train_data.tolist()\n",
    "# Train_labels = Train_labels.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to convert serialized images to .png format for visualization of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in range(len(Train_data)):\n",
    "#     img = []\n",
    "#     l = Train_data[x]\n",
    "#     j=0\n",
    "#     k=28\n",
    "#     for i in range(28):\n",
    "#         img.append(l[j:k])\n",
    "#         j += 28\n",
    "#         k += 28\n",
    "#     cv2.imwrite('image'+str(x+1)+'.png', np.array(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to binarize grayscale images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Explanation:</b> This was an attempt to normalize pixel values by fixing values < 127 to 0 and >=128 to 1. However, this showed a drop in accuracy and hence, was not included in the final pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def binarize(BTrain_data, BTest_data):\n",
    "#     for i in range(len(BTrain_data)):\n",
    "#         for j in range(len(BTrain_data[0])):\n",
    "#             if BTrain_data[i][j] < 127:\n",
    "#                 BTrain_data[i][j] = 0\n",
    "#             else:\n",
    "#                 BTrain_data[i][j] = 1\n",
    "\n",
    "#     for i in range(len(BTest_data)):\n",
    "#         for j in range(len(BTest_data[0])):\n",
    "#             if BTest_data[i][j] < 127:\n",
    "#                 BTest_data[i][j] = 0\n",
    "#             else:\n",
    "#                 BTest_data[i][j] = 1\n",
    "\n",
    "# BTrain_data = copy.deepcopy(Train_data)\n",
    "# BTest_data = copy.deepcopy(Test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to train the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parameters: </b> train_data => numpy array which contains training data, train_labels => numpy array containing labels of train data, test_data => numpy array containing test data <br>\n",
    "<b>Return Value: </b> pred_labels => numpy array of predicted labels for test data, classifier => classifier object trained on train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Explanation:</b> Different types of in-built classifiers were tried on the given data. _Logistic Regression_ performed the best for both training and validation data and hence was chosen as the final classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainClassifier(train_data, train_labels, test_data):\n",
    "    classifier = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "#     classifier = GaussianNB()\n",
    "#     classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5))\n",
    "#     classifier = AdaBoostClassifier()\n",
    "#     classifier = MLPClassifier()\n",
    "#     classifier = DecisionTreeClassifier()\n",
    "#     classifier = SVC(gamma='auto')\n",
    "#     classifier = LinearSVC()\n",
    "    classifier.fit(train_data, train_labels)\n",
    "#     pred_prob = classifier.predict_proba(test_data)\n",
    "    pred_labels = classifier.predict(test_data)\n",
    "    return pred_labels, classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to calculate accuracy of predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parameters:</b> test_labels => actual labels, pred_labels => predicted labels <br>\n",
    "<b>Return Value: </b> accuracy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAccuracy(test_labels, pred_labels):\n",
    "    hit = 0\n",
    "    for i in range(len(test_labels)):\n",
    "        if test_labels[i] == pred_labels[i]:\n",
    "            hit += 1\n",
    "    return hit/len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to split training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parameters:</b> D => training images, D_labels => labels of images, trainp => percentage split expressed in decimal, rseed (default parameter) => random seed for pseudo-randomization <br>\n",
    "<b>Return Value: </b> train_data => splitted train data, train_labels => labels of splitted data, validation_data => remaining part of original data to be used as validation set, validation_labels => labels for validation_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(D, D_labels, trainp, rseed=42):\n",
    "    random.Random(rseed).shuffle(D)\n",
    "    random.Random(rseed).shuffle(D_labels)\n",
    "    x = int(trainp*len(D))\n",
    "    train_data = D[:x]\n",
    "    train_labels = D_labels[:x]\n",
    "    validation_data = D[x:]\n",
    "    validation_labels = D_labels[x:]\n",
    "    return train_data, train_labels, validation_data, validation_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to perform Cross Validation on Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parameters:</b> pdata => training data, train_labels => labels of p_data, q (default parameter) => No. of splits of training data<br>\n",
    "<b>Return Value: </b> average accuracy, acc => list of accuracies across all folds, fold_index => index values for all folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performCrossValidation(pdata, train_labels, q=5):\n",
    "    fold = len(pdata)//q\n",
    "    j = 0\n",
    "    k = fold\n",
    "    acc = []\n",
    "    Xs_train = []\n",
    "    ys_train = []\n",
    "    all_classifiers = []\n",
    "    for i in range(q):\n",
    "        Xs_test = pdata[j:k]\n",
    "        ys_test = train_labels[j:k]\n",
    "        if j>0:\n",
    "            Xs_train = pdata[:j]\n",
    "            ys_train = train_labels[:j]\n",
    "        Xs_train += pdata[k:]\n",
    "        ys_train += train_labels[k:]\n",
    "        pred_labels, classifier = trainClassifier(np.array(Xs_train), np.array(ys_train), np.array(Xs_test))\n",
    "        all_classifiers.append(classifier)\n",
    "        acc.append(calcAccuracy(ys_test, pred_labels))\n",
    "        j += fold\n",
    "        if i == 3:\n",
    "            k = len(pdata)\n",
    "        else:\n",
    "            k += fold\n",
    "    return acc, all_classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to split training data into 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels, validation_data, validation_labels = splitData(Train_data, Train_labels, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to calculate accuracy for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8025"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l, c = trainClassifier(train_data, train_labels, validation_data)\n",
    "calcAccuracy(validation_labels, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script for 5-fold cross validation function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "all_acc, all_classifiers = performCrossValidation(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7660714285714286, 0.7821428571428571, 0.7857142857142857, 0.7741071428571429, 0.7946428571428571]\n",
      "0.7805357142857143\n"
     ]
    }
   ],
   "source": [
    "print(all_acc)\n",
    "print(sum(all_acc)/len(all_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to select the best classifer and calculate accuracy for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78875"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = np.argmax(all_acc)\n",
    "best_classifier = all_classifiers[pos]\n",
    "\n",
    "pred_labels = best_classifier.predict(validation_data)\n",
    "calcAccuracy(validation_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script for obtaining predicted labels for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels = best_classifier.predict(Test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script to write the predicted labels into .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Udit_Pant.csv', 'w') as csvobj:\n",
    "    cwriter = csv.writer(csvobj, delimiter = ',')\n",
    "    cwriter.writerow(['image_index', 'class'])\n",
    "    for i in range(len(final_labels)):\n",
    "        cwriter.writerow([i, final_labels[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Image augmentation - https://imgaug.readthedocs.io/en/latest/source/examples_basics.html#a-simple-and-common-augmentation-sequence\n",
    "2. scikit-learn documentation -  https://scikit-learn.org/stable/index.html\n",
    "3. Stack Overflow - https://stackoverflow.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
